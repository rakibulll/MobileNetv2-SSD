{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "current.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbsreEfjnQtP"
      },
      "source": [
        "# Implementation of MobileNetv2+SSD<br>\n",
        "This is an implementation of the MobileNetv2 + SSD architecture for a relatively simpler task of determining bounding boxes for MNIST images embedded in a box. Each box contains only one digit(28x28 MNIST embedded into a 224x224 box) as of now, but the number of predictions per image can be expanded easily (the training outputs need to modified). Also, no data augmentation has been used till now (Colab kept crashing when I increased the dataset size beyond 1000, so the initial amount of data present was sufficient. The crashes might have been due to high traffic, but I haven't confirmed it).<p>\n",
        "In the earlier implementation, the ground truth data contained information about only one bounding box, which meant only one prediction per image (reference in README). For me, it also reduced the training signal and the model was overfitting. So I changed the outputs to a prediction for each default box (as it should be, from what I understood from the SSD paper). Although the initial implementation is good for the purposes for understanding the model.\n",
        "\n",
        "Comments mentioned throughout the code mention what needs to change if the model inputs or outputs are changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdL2AL8yAi00"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.8 bottleneck"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qumy7Fegdc6L",
        "outputId": "9f5fa69a-91f9-4c2d-fdfd-fc9887912b1a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras==2.8 in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Collecting bottleneck\n",
            "  Downloading Bottleneck-1.3.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
            "\u001b[K     |████████████████████████████████| 355 kB 35.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bottleneck) (1.21.6)\n",
            "Installing collected packages: bottleneck\n",
            "Successfully installed bottleneck-1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hvSY3X-AeFP"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "import numpy.matlib\n",
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from scipy.special import softmax\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import bottleneck"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ],
      "metadata": {
        "id": "3wFty_P6dfBB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFmrlFJ8uKCe"
      },
      "source": [
        "Define Bottleneck Residual layer for MobileNet<br>\n",
        "Using the same parameters as mentioned in the paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmwhyyS7CFyK"
      },
      "source": [
        "class Bottleneck(keras.Model):\n",
        "  def __init__(\n",
        "      self,\n",
        "      expansion,\n",
        "      stride,\n",
        "      block_id,\n",
        "      filters,\n",
        "      alpha=1,\n",
        "      ):\n",
        "    super(Bottleneck,self).__init__(name = \"Bottleneck_\" + block_id)\n",
        "    self.stride = stride\n",
        "    self.expansion = expansion\n",
        "    self.alpha = alpha\n",
        "    self.output_channels = self.alpha * filters\n",
        "    self.out = None # there was some problem with the eager execution\n",
        "\n",
        "    prefix =  'Bottleneck_{}_'.format(block_id)\n",
        "    self.prefix = prefix\n",
        "    # expansion\n",
        "    self.expand_BN = layers.BatchNormalization(name = prefix + 'expand_BN')\n",
        "    self.expand_ReLU = layers.ReLU(max_value=6, name = prefix + 'expand_ReLU')\n",
        "\n",
        "    #conv\n",
        "    self.Conv = layers.DepthwiseConv2D(\n",
        "        kernel_size = 3,\n",
        "        padding='same',\n",
        "        strides = self.stride,\n",
        "        use_bias = False,\n",
        "        name = prefix + 'conv')\n",
        "    self.Conv_BN = layers.BatchNormalization(name = prefix + 'conv_BN')\n",
        "    self.Conv_ReLU = layers.ReLU(max_value=6, name = prefix + 'conv_ReLU')\n",
        "\n",
        "    #project\n",
        "    self.project = layers.Conv2D(\n",
        "        filters = self.output_channels,\n",
        "        kernel_size = 1,\n",
        "        use_bias = False,\n",
        "        name = 'contract')\n",
        "    self.project_BN = layers.BatchNormalization(name = prefix + 'contract_BN')\n",
        "\n",
        "    # dimensions need to be the same for residual connection\n",
        "    self.residual = layers.Add(name=prefix + 'residual')\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    self.d = input_shape[-1]\n",
        "    \n",
        "    self.expand = layers.Conv2D(\n",
        "        filters = self.expansion*self.d,\n",
        "        kernel_size = 1,\n",
        "        use_bias = False,\n",
        "        name = self.prefix+'expand')\n",
        "\n",
        "      \n",
        "  def call(self, inputs):\n",
        "\n",
        "    x = self.expand(inputs)\n",
        "    x = self.expand_BN(x)\n",
        "    x = self.expand_ReLU(x)\n",
        "    self.out = x\n",
        "    \n",
        "    x = self.Conv(x)\n",
        "    x = self.Conv_BN(x)\n",
        "    x = self.Conv_ReLU(x)\n",
        "\n",
        "    x = self.project(x)\n",
        "    x = self.project_BN(x)\n",
        "\n",
        "    if self.output_channels == self.d and self.stride == 1:\n",
        "      x = self.residual([inputs,x])\n",
        "\n",
        "    return x\n",
        "\n",
        "  def model(self):\n",
        "      x = keras.Input(shape=(28,28,3))\n",
        "      return keras.Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfMYYpWpuQj4"
      },
      "source": [
        "Define MobileNetv2<br>\n",
        "Same components as mentioned in the paper (the input image dimensions are a bit different)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYGagWE8T2Et"
      },
      "source": [
        "#using the architecture mentioned in the paper\n",
        "class MobileNetv2(keras.Model):\n",
        "  def __init__(self, k = 11):\n",
        "    super(MobileNetv2,self).__init__()\n",
        "    self.conv_inp = layers.Conv2D(\n",
        "        filters = 32,\n",
        "        kernel_size = 3,\n",
        "        strides = (2,2),\n",
        "        padding='valid',\n",
        "        use_bias = False,\n",
        "        name = 'conv'\n",
        "    )\n",
        "    self.k = k    \n",
        "\n",
        "    self.pad = layers.ZeroPadding2D(padding=2,name='pad')\n",
        "    self.BN = layers.BatchNormalization(name='BN')\n",
        "    self.ReLU = layers.ReLU(max_value = 6, name = 'ReLU')\n",
        "    \n",
        "    self.B1_1 = Bottleneck(expansion = 1, filters = 16, stride = 1, block_id = 'B1_1')\n",
        "\n",
        "    self.B2_1 = Bottleneck(expansion = 6, filters = 24, stride = 2, block_id = 'B2_1')\n",
        "    self.B2_2 = Bottleneck(expansion = 6, filters = 24, stride = 1, block_id = 'B2_2')\n",
        "\n",
        "    self.B3_1 = Bottleneck(expansion = 6, filters = 32, stride = 2, block_id = 'B3_1')\n",
        "    self.B3_2 = Bottleneck(expansion = 6, filters = 32, stride = 1, block_id = 'B3_2')\n",
        "    self.B3_3 = Bottleneck(expansion = 6, filters = 32, stride = 1, block_id = 'B3_3')\n",
        "\n",
        "    self.B4_1 = Bottleneck(expansion = 6, filters = 64, stride = 2, block_id = 'B4_1')\n",
        "    self.B4_2 = Bottleneck(expansion = 6, filters = 64, stride = 1, block_id = 'B4_2')\n",
        "    self.B4_3 = Bottleneck(expansion = 6, filters = 64, stride = 1, block_id = 'B4_3')\n",
        "    self.B4_4 = Bottleneck(expansion = 6, filters = 64, stride = 1, block_id = 'B4_4')\n",
        "\n",
        "    self.B5_1 = Bottleneck(expansion = 6, filters = 96, stride = 1, block_id = 'B5_1')\n",
        "    self.B5_2 = Bottleneck(expansion = 6, filters = 96, stride = 1, block_id = 'B5_2')\n",
        "    self.B5_3 = Bottleneck(expansion = 6, filters = 96, stride = 1, block_id = 'B5_3')\n",
        "\n",
        "    self.B6_1 = Bottleneck(expansion = 6, filters = 160, stride = 2, block_id = 'B6_1')\n",
        "    self.B6_2 = Bottleneck(expansion = 6, filters = 160, stride = 1, block_id = 'B6_2')\n",
        "    self.B6_3 = Bottleneck(expansion = 6, filters = 160, stride = 1, block_id = 'B6_3')\n",
        "\n",
        "    self.B7_1 = Bottleneck(expansion = 6, filters = 320, stride = 1, block_id = 'B7_1')\n",
        "\n",
        "    self.conv_out = layers.Conv2D(\n",
        "        filters = 1280,\n",
        "        kernel_size = 1,\n",
        "        strides = (1,1),\n",
        "        use_bias = False,\n",
        "        name = 'conv_out'\n",
        "    )\n",
        "    self.avgpool = layers.AveragePooling2D(\n",
        "        pool_size = (7,7),\n",
        "        name='avg_pool'\n",
        "        )\n",
        "    \n",
        "    self.conv_seg = layers.Conv2D(\n",
        "        filters = self.k,\n",
        "        kernel_size = 1,\n",
        "        strides = (1,1),\n",
        "        use_bias = False,\n",
        "        name = 'conv_seg'\n",
        "    )\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.conv_inp(inputs)\n",
        "    x = self.BN(x)\n",
        "    x = self.ReLU(x)\n",
        "\n",
        "    x = self.B1_1(x)\n",
        "    x = self.B2_1(x)\n",
        "    x = self.B2_2(x)\n",
        "\n",
        "    x = self.B3_1(x)\n",
        "    x = self.B3_2(x)\n",
        "    x = self.B3_3(x)\n",
        "    \n",
        "    x = self.B4_1(x)\n",
        "    x = self.B4_2(x)\n",
        "    x = self.B4_3(x)\n",
        "    x = self.B4_4(x)\n",
        "    \n",
        "    x = self.B5_1(x)\n",
        "    x = self.B5_2(x)\n",
        "    x = self.B5_3(x)\n",
        "    \n",
        "    x = self.B6_1(x)\n",
        "    x = self.B6_2(x)\n",
        "    x = self.B6_3(x)\n",
        "    \n",
        "    x = self.B7_1(x)\n",
        "\n",
        "    x = self.conv_out(x)\n",
        "    x = self.avgpool(x)\n",
        "    c4 = self.conv_seg(x)\n",
        "\n",
        "    return c4\n",
        "\n",
        "  def model(self):\n",
        "      x = keras.Input(shape=(224,224,3))\n",
        "\n",
        "      return keras.Model(inputs=x, outputs=self.call(x))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05i7363EYwmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d0ed91-6aff-4bdd-c04e-f2ca01ea3cad"
      },
      "source": [
        "MobileNetv2().model().summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv (Conv2D)               (None, 111, 111, 32)      864       \n",
            "                                                                 \n",
            " BN (BatchNormalization)     (None, 111, 111, 32)      128       \n",
            "                                                                 \n",
            " ReLU (ReLU)                 (None, 111, 111, 32)      0         \n",
            "                                                                 \n",
            " Bottleneck_B1_1 (Bottleneck  (None, 111, 111, 16)     2144      \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B2_1 (Bottleneck  (None, 56, 56, 24)       5568      \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B2_2 (Bottleneck  (None, 56, 56, 24)       9456      \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B3_1 (Bottleneck  (None, 28, 28, 32)       10640     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B3_2 (Bottleneck  (None, 28, 28, 32)       15680     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B3_3 (Bottleneck  (None, 28, 28, 32)       15680     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B4_1 (Bottleneck  (None, 14, 14, 64)       21952     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B4_2 (Bottleneck  (None, 14, 14, 64)       55936     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B4_3 (Bottleneck  (None, 14, 14, 64)       55936     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B4_4 (Bottleneck  (None, 14, 14, 64)       55936     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B5_1 (Bottleneck  (None, 14, 14, 96)       68352     \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B5_2 (Bottleneck  (None, 14, 14, 96)       120768    \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B5_3 (Bottleneck  (None, 14, 14, 96)       120768    \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B6_1 (Bottleneck  (None, 7, 7, 160)        157888    \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B6_2 (Bottleneck  (None, 7, 7, 160)        324160    \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B6_3 (Bottleneck  (None, 7, 7, 160)        324160    \n",
            " )                                                               \n",
            "                                                                 \n",
            " Bottleneck_B7_1 (Bottleneck  (None, 7, 7, 320)        478400    \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_out (Conv2D)           (None, 7, 7, 1280)        409600    \n",
            "                                                                 \n",
            " avg_pool (AveragePooling2D)  (None, 1, 1, 1280)       0         \n",
            "                                                                 \n",
            " conv_seg (Conv2D)           (None, 1, 1, 11)          14080     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,268,096\n",
            "Trainable params: 2,236,480\n",
            "Non-trainable params: 31,616\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II03ZRu17FnE"
      },
      "source": [
        "Defining SSD<br>\n",
        "The default number of boxes per layer and resolution of each layer is different, since we are working with MNIST data and 224x224 image sizes.<p>\n",
        "To change the number of boxes per layer and layerWidths, some constraints need to be kept in mind which are mentioned in the later sections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYD2gfR9O8L0"
      },
      "source": [
        "class SSD(keras.Model):\n",
        "  def __init__(self, numBoxes=[4,6,6,6,4,4], layerWidth=[28,14,7,4,2,1], k = 10+1+4):\n",
        "    super(SSD,self).__init__()\n",
        "    self.classes = k\n",
        "    self.featureMaps = 6\n",
        "    self.MobileNet = MobileNetv2(k=k)\n",
        "\n",
        "    # mark bottleneck_6_1 onwards as non trainable\n",
        "    for layer in self.MobileNet.layers[-7:]:\n",
        "      layer.trainable=False\n",
        "    \n",
        "    # For bottleneck_5_3, mark layers beyond conv as non runnable\n",
        "    # layers in bottleneck_5_3: ['Bottleneck_B5_3_expand_BN', 'Bottleneck_B5_3_expand_ReLU', 'Bottleneck_B5_3_conv', 'Bottleneck_B5_3_conv_BN', \n",
        "    # 'Bottleneck_B5_3_conv_ReLU', 'contract', 'Bottleneck_B5_3_contract_BN', 'Bottleneck_B5_3_residual', 'Bottleneck_B5_3_expand']\n",
        "    for layer in self.MobileNet.layers[-8].layers[2:-1]:\n",
        "      layer.trainable=False\n",
        "\n",
        "    self.numBoxes = numBoxes\n",
        "    self.layerWidth = layerWidth\n",
        "    self.features = [None for _ in range(self.featureMaps)]\n",
        "    self.classifiers = [None for _ in range(self.featureMaps)]\n",
        "    \n",
        "    self.conv1_1 = layers.Conv2D(256,1,name='SSD_conv_1_1')\n",
        "    self.conv1_2 = layers.Conv2D(512,3,strides=(2,2),padding='same',name='SSD_conv_1_2')\n",
        "\n",
        "    self.conv2_1 = layers.Conv2D(128,1,name='SSD_conv_2_1')\n",
        "    self.conv2_2 = layers.Conv2D(256,3,strides=(2,2),padding='same',name='SSD_conv_2_2')\n",
        "    \n",
        "    self.conv3_1 = layers.Conv2D(128,1,name='SSD_conv_3_1')\n",
        "    self.conv3_2 = layers.Conv2D(256,3,strides=(1,1),name='SSD_conv_3_2')\n",
        "    \n",
        "    self.conv4_1 = layers.Conv2D(128,1,name='SSD_conv_4_1')\n",
        "    self.conv4_2 = layers.Conv2D(256,2,strides=(1,1),name='SSD_conv_4_2') # changed the kernel size to 2 since the output of the previous layer has width 3\n",
        "\n",
        "    self.conv = []\n",
        "    self.reshape = []\n",
        "    for i in range(self.featureMaps):\n",
        "      self.conv.append(layers.Conv2D(self.numBoxes[i]*self.classes,3,padding='same',name='Classification_'+str(i)))\n",
        "      self.reshape.append(layers.Reshape((self.layerWidth[i]* self.layerWidth[i] * self.numBoxes[i],self.classes),name='Reshape_classification_'+str(i)))\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.MobileNet.build(input_shape)\n",
        "  \n",
        "  def call(self,inputs):\n",
        "    x = inputs\n",
        "    x = self.MobileNet(x)\n",
        "\n",
        "    # get the convolved images at different resolutions\n",
        "    self.features[0] = self.MobileNet.get_layer('Bottleneck_B4_1').out\n",
        "    self.features[1] = self.MobileNet.get_layer('Bottleneck_B5_3').out\n",
        "    self.features[2] = self.conv1_2(self.conv1_1(self.features[1]))\n",
        "    self.features[3] = self.conv2_2(self.conv2_1(self.features[2]))\n",
        "    self.features[4] = self.conv3_2(self.conv3_1(self.features[3]))\n",
        "    self.features[5] = self.conv4_2(self.conv4_1(self.features[4]))\n",
        "\n",
        "    for i in range(self.featureMaps):\n",
        "    # for each feature map, create predictions according to the number of boxes for that layer and the number of output channels\n",
        "      x = self.conv[i](self.features[i])\n",
        "      x = self.reshape[i](x)\n",
        "      self.classifiers[i] = x\n",
        "    \n",
        "    # concatenate all the classifiers\n",
        "    x = layers.concatenate(self.classifiers, axis = -2, name='concatenate')\n",
        "    return x\n",
        "\n",
        "\n",
        "  def model(self):\n",
        "      x = keras.Input(shape=(224,224,3))\n",
        "\n",
        "      return keras.Model(inputs=x, outputs=self.call(x))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29A_FW-GxK4t"
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "# the first 2 dimensions should be equal to width of the output from the bottleneck expand ReLU at the (4,1) and (5,3) respectively.\n",
        "# the dimensions after the second one are determined by the convolutions written inside the SSD (conv1_2, conv2_2, conv3_3, conv4_2)\n",
        "layerWidths = [28,14,7,4,2,1]\n",
        "numBoxes = [3,3,3,3,3,3]\n",
        "assert len(numBoxes) == len(layerWidths) # numBoxes for each layer and each layer has a specific width\n",
        "outputChannels = NUM_CLASSES + 1 + 4 # 10 classes + background + cx,cy,h,w\n",
        "assert outputChannels - NUM_CLASSES == 5"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmOfPVIjCkuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c53e83-aa54-44c8-bd30-43d452cce1c1"
      },
      "source": [
        "model = SSD(numBoxes=numBoxes, layerWidth=layerWidths, k = outputChannels)\n",
        "model.model().summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv (Conv2D)                  (None, 111, 111, 32  864         ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " BN (BatchNormalization)        (None, 111, 111, 32  128         ['conv[0][0]']                   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " ReLU (ReLU)                    (None, 111, 111, 32  0           ['BN[0][0]']                     \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Bottleneck_B1_1 (Bottleneck)   (None, 111, 111, 16  2144        ['ReLU[0][0]']                   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Bottleneck_B2_1 (Bottleneck)   (None, 56, 56, 24)   5568        ['Bottleneck_B1_1[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B2_2 (Bottleneck)   (None, 56, 56, 24)   9456        ['Bottleneck_B2_1[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B3_1 (Bottleneck)   (None, 28, 28, 32)   10640       ['Bottleneck_B2_2[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B3_2 (Bottleneck)   (None, 28, 28, 32)   15680       ['Bottleneck_B3_1[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B3_3 (Bottleneck)   (None, 28, 28, 32)   15680       ['Bottleneck_B3_2[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B4_1 (Bottleneck)   (None, 14, 14, 64)   21952       ['Bottleneck_B3_3[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B4_2 (Bottleneck)   (None, 14, 14, 64)   55936       ['Bottleneck_B4_1[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B4_3 (Bottleneck)   (None, 14, 14, 64)   55936       ['Bottleneck_B4_2[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B4_4 (Bottleneck)   (None, 14, 14, 64)   55936       ['Bottleneck_B4_3[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B5_1 (Bottleneck)   (None, 14, 14, 96)   68352       ['Bottleneck_B4_4[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B5_2 (Bottleneck)   (None, 14, 14, 96)   120768      ['Bottleneck_B5_1[0][0]']        \n",
            "                                                                                                  \n",
            " Bottleneck_B5_3_expand (Conv2D  (None, 14, 14, 576)  55296      ['Bottleneck_B5_2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " Bottleneck_B5_3_expand_BN (Bat  (None, 14, 14, 576)  2304       ['Bottleneck_B5_3_expand[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " Bottleneck_B5_3_expand_ReLU (R  (None, 14, 14, 576)  0          ['Bottleneck_B5_3_expand_BN[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " SSD_conv_1_1 (Conv2D)          (None, 14, 14, 256)  147712      ['Bottleneck_B5_3_expand_ReLU[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " SSD_conv_1_2 (Conv2D)          (None, 7, 7, 512)    1180160     ['SSD_conv_1_1[0][0]']           \n",
            "                                                                                                  \n",
            " SSD_conv_2_1 (Conv2D)          (None, 7, 7, 128)    65664       ['SSD_conv_1_2[0][0]']           \n",
            "                                                                                                  \n",
            " SSD_conv_2_2 (Conv2D)          (None, 4, 4, 256)    295168      ['SSD_conv_2_1[0][0]']           \n",
            "                                                                                                  \n",
            " SSD_conv_3_1 (Conv2D)          (None, 4, 4, 128)    32896       ['SSD_conv_2_2[0][0]']           \n",
            "                                                                                                  \n",
            " Bottleneck_B4_1_expand (Conv2D  (None, 28, 28, 192)  6144       ['Bottleneck_B3_3[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " SSD_conv_3_2 (Conv2D)          (None, 2, 2, 256)    295168      ['SSD_conv_3_1[0][0]']           \n",
            "                                                                                                  \n",
            " Bottleneck_B4_1_expand_BN (Bat  (None, 28, 28, 192)  768        ['Bottleneck_B4_1_expand[0][0]'] \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " SSD_conv_4_1 (Conv2D)          (None, 2, 2, 128)    32896       ['SSD_conv_3_2[0][0]']           \n",
            "                                                                                                  \n",
            " Bottleneck_B4_1_expand_ReLU (R  (None, 28, 28, 192)  0          ['Bottleneck_B4_1_expand_BN[0][0]\n",
            " eLU)                                                            ']                               \n",
            "                                                                                                  \n",
            " SSD_conv_4_2 (Conv2D)          (None, 1, 1, 256)    131328      ['SSD_conv_4_1[0][0]']           \n",
            "                                                                                                  \n",
            " Classification_0 (Conv2D)      (None, 28, 28, 45)   77805       ['Bottleneck_B4_1_expand_ReLU[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " Classification_1 (Conv2D)      (None, 14, 14, 45)   233325      ['Bottleneck_B5_3_expand_ReLU[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " Classification_2 (Conv2D)      (None, 7, 7, 45)     207405      ['SSD_conv_1_2[0][0]']           \n",
            "                                                                                                  \n",
            " Classification_3 (Conv2D)      (None, 4, 4, 45)     103725      ['SSD_conv_2_2[0][0]']           \n",
            "                                                                                                  \n",
            " Classification_4 (Conv2D)      (None, 2, 2, 45)     103725      ['SSD_conv_3_2[0][0]']           \n",
            "                                                                                                  \n",
            " Classification_5 (Conv2D)      (None, 1, 1, 45)     103725      ['SSD_conv_4_2[0][0]']           \n",
            "                                                                                                  \n",
            " Reshape_classification_0 (Resh  (None, 2352, 15)    0           ['Classification_0[0][0]']       \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " Reshape_classification_1 (Resh  (None, 588, 15)     0           ['Classification_1[0][0]']       \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " Reshape_classification_2 (Resh  (None, 147, 15)     0           ['Classification_2[0][0]']       \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " Reshape_classification_3 (Resh  (None, 48, 15)      0           ['Classification_3[0][0]']       \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " Reshape_classification_4 (Resh  (None, 12, 15)      0           ['Classification_4[0][0]']       \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " Reshape_classification_5 (Resh  (None, 3, 15)       0           ['Classification_5[0][0]']       \n",
            " ape)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3150, 15)     0           ['Reshape_classification_0[0][0]'\n",
            "                                                                 , 'Reshape_classification_1[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'Reshape_classification_2[0][0]'\n",
            "                                                                 , 'Reshape_classification_3[0][0]\n",
            "                                                                 ',                               \n",
            "                                                                  'Reshape_classification_4[0][0]'\n",
            "                                                                 , 'Reshape_classification_5[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,507,342\n",
            "Trainable params: 3,492,494\n",
            "Non-trainable params: 14,848\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RA7NxfQ7_G6"
      },
      "source": [
        "Creating boxes and IoU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRYi7Ez7UzpH"
      },
      "source": [
        "# I have used less varying custom scales and aspect ratios here, since the dataset is already uniform\n",
        "#IMPORTANT: before changing the scales and aspect ratios, read the comment below\n",
        "\n",
        "# number of scales is equal to the number of different resolutions ie num of layer widths\n",
        "# for a given resolution, we have different aspect ratios\n",
        "# num(scales) = num(layerWidth) = num(numBoxes) and num(asp_ratios) = numBoxes[i]\n",
        "MinScale = .1 # Min and Max scale given as percentage\n",
        "MaxScale = 1.5\n",
        "scales = [ MinScale + x/len(layerWidths) * (MaxScale-MinScale) for x in range(len(layerWidths)) ]\n",
        "scales = scales[::-1] # reversing the order because the layerWidths go from high to low (lower to higher resoltuion)\n",
        "\n",
        "asp = [0.5,1.0,1.5]\n",
        "asp1 = [x**0.5 for x in asp]\n",
        "asp2 = [1/x for x in asp1]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwR_TIbzYCix"
      },
      "source": [
        "IMG_SIZE = 224"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA_IhnyrUl4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f0db0d-5f22-4ee8-abd7-0a9d19b43e11"
      },
      "source": [
        "# should be equal to the 1st dimension in the output layer of the SSD model\n",
        "BOXES = sum([a*a*b for a,b in zip(layerWidths,numBoxes)])\n",
        "centres = np.zeros((BOXES,2))\n",
        "hw = np.zeros((BOXES,2))\n",
        "boxes = np.zeros((BOXES,4))\n",
        "print(BOXES)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A1xGMrXVX18"
      },
      "source": [
        "# calculating the default box centres and height, width\n",
        "idx = 0\n",
        "\n",
        "for gridSize, numBox, scale in zip(layerWidths,numBoxes,scales):\n",
        "  step_size = IMG_SIZE*1.0/gridSize\n",
        "  for i in range(gridSize):\n",
        "    for j in range(gridSize):\n",
        "      pos = idx + (i*gridSize+j) * numBox\n",
        "      # centre is the same for all aspect ratios(=numBox)\n",
        "      centres[ pos : pos + numBox , :] = i*step_size + step_size/2, j*step_size + step_size/2\n",
        "      # height and width vary according to the scale and aspect ratio\n",
        "      # zip asepct ratios and then scale them by the scaling factor\n",
        "      hw[ pos : pos + numBox , :] = np.multiply(gridSize*scale, np.squeeze(np.dstack([asp1,asp2]),axis=0))[:numBox,:]\n",
        "\n",
        "  idx += gridSize*gridSize*numBox "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp9CrasJhGXI"
      },
      "source": [
        "# (x,y) co-ordinates of top left and bottom right\n",
        "# This actually is not used anywhere. centres[] and hw[] are a good enough substitute\n",
        "boxes[:,0] = centres[:,0] - hw[:,0]/2\n",
        "boxes[:,1] = centres[:,1] - hw[:,1]/2\n",
        "boxes[:,2] = centres[:,0] + hw[:,0]/2\n",
        "boxes[:,3] = centres[:,1] + hw[:,1]/2"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJSIPHPMh3N2"
      },
      "source": [
        "# calculate IoU for a set of search boxes and default boxes\n",
        "def IoU(box1, box2):\n",
        "  box1 = box1.astype(np.float64)\n",
        "  box2 = box2.astype(np.float64)\n",
        "  # find the left and right co-ordinates of the edges. Min should be less than Max for non zero overlap\n",
        "  xmin = np.maximum(box1[:,0],box2[:,0])\n",
        "  xmax = np.minimum(box1[:,2],box2[:,2])\n",
        "  ymin = np.maximum(box1[:,1],box2[:,1])\n",
        "  ymax = np.minimum(box1[:,3],box2[:,3])\n",
        "\n",
        "  intersection = np.abs(np.maximum(xmax-xmin,0) * np.maximum(ymax-ymin,0))\n",
        "  boxArea1 = np.abs((box1[:,2] - box1[:,0]) * (box1[:,3] - box1[:,1]))\n",
        "  boxArea2 = np.abs((box2[:,2] - box2[:,0]) * (box2[:,3] - box2[:,1]))\n",
        "  unionArea = boxArea1 + boxArea2 - intersection\n",
        "  assert (unionArea > 0).all()\n",
        "  iou = intersection / unionArea\n",
        "\n",
        "  return iou"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOcpxxIQipbA"
      },
      "source": [
        "# give the index of the box correpsonding to the IoUs > threshold (=0.5) \n",
        "def bestIoU(searchBox):\n",
        "  return np.argwhere(IoU(numpy.matlib.repmat(searchBox,BOXES,1), boxes) > 0.5)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm2k4c5Ik_BX"
      },
      "source": [
        "Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h07BGB7-k9te"
      },
      "source": [
        "TRAINSIZE = 600\n",
        "TESTSIZE = 100"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkZPTKgGq08N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b663c1-2189-4bd9-bf3e-a2adf64c48dc"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train[:TRAINSIZE , : , :]\n",
        "y_train = y_train[:TRAINSIZE]\n",
        "x_test = x_test[:TESTSIZE , : , :]\n",
        "y_test = y_test[:TESTSIZE]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEgx1Sdcq7yJ"
      },
      "source": [
        "# take mnist x and y pairs and convert to input, output pairs for the MobileNetv2+SSD model\n",
        "def convert(x,y):\n",
        "  MNIST_SIZE = x.shape[-1]\n",
        "  # create a 2D array of top left corners for the mnist image to be placed\n",
        "  corner = np.random.randint(IMG_SIZE - MNIST_SIZE, size=(x.shape[0],2))\n",
        "\n",
        "  # create a blank canvas for the input with the required dimension\n",
        "  input = np.zeros((x.shape[0], IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "  # replacing a part by RGB version of MNIST\n",
        "  for i in range(x.shape[0]):\n",
        "    lx = int(corner[i,0])\n",
        "    ly = int(corner[i,1])\n",
        "    input[i,lx:lx + MNIST_SIZE, ly:ly+MNIST_SIZE,:] = np.repeat(np.expand_dims(np.array(x[i,:,:]),axis=-1),3,axis=-1)\n",
        "\n",
        "  # for each default box, there are 5 values: class number and delta cx,cy,h,w\n",
        "  output = np.zeros((y.shape[0],BOXES,1+4))\n",
        "  output[:,:,0] = NUM_CLASSES # defaulting class labels for all boxes to background initially\n",
        "  for i in range(x.shape[0]):\n",
        "    bbox = np.zeros(4)\n",
        "    bbox[:2] = corner[i]\n",
        "    bbox[2:] = corner[i] + (MNIST_SIZE,MNIST_SIZE)\n",
        "    # for all default boxes which have IoU > threshold, set the delta values and class number\n",
        "    box_idx = bestIoU(bbox).astype(np.uint16)\n",
        "    output[i,box_idx,0] = y[i]\n",
        "    output[i,box_idx,1] = (bbox[0] + bbox[2])/2.0 - centres[box_idx,0]\n",
        "    output[i,box_idx,2] = (bbox[1] + bbox[3])/2.0 - centres[box_idx,1]\n",
        "    output[i,box_idx,3] = MNIST_SIZE - hw[box_idx,0]\n",
        "    output[i,box_idx,4] = MNIST_SIZE - hw[box_idx,1]\n",
        "\n",
        "  return input, output\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk_z17wV3Bj5"
      },
      "source": [
        "test_x, test_y = convert(x_test,y_test)\n",
        "train_x, train_y = convert(x_train,y_train)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAwnJnu4qE0P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "36105aba-89ce-4e12-ad01-2ab01a6b2785"
      },
      "source": [
        "# checking if the inputs prepared are correct or not\n",
        "r = np.random.randint(0,train_x.shape[0])\n",
        "img = train_x[r,:,:,:].copy()\n",
        "img_y = train_y[r]\n",
        "\n",
        "im = np.array(Image.fromarray(img.astype(np.uint8)))\n",
        "fig,ax = plt.subplots(1)\n",
        "ax.imshow(im)\n",
        "\n",
        "# find all boxes where class label is not background\n",
        "idx = np.argwhere(img_y[:,0] != NUM_CLASSES)[:,0]\n",
        "print('Number of boxes with IoU > threshold (0.5):',idx.shape[0])\n",
        "print('Green box: ground truth. Red box: default boxes with IoU < threshold (0.5)')\n",
        "\n",
        "#calculating the ground truth bounding boxes\n",
        "gt = np.zeros(4,dtype=np.uint16)\n",
        "gt[:2] = (img_y[idx[0],1:3] + centres[idx[0],:2])\n",
        "gt[2:] = (img_y[idx[0],3:] + hw[idx[0],:])\n",
        "\n",
        "# for some reason, x and y are inverted\n",
        "rect = patches.Rectangle((gt[1]-gt[3]/2,gt[0]-gt[2]/2),gt[3],gt[2],linewidth=5,edgecolor='g',facecolor='none')\n",
        "ax.add_patch(rect)\n",
        "\n",
        "# showing all the boxes with IoU > 0.5\n",
        "for i in idx:\n",
        "  rect = patches.Rectangle((centres[i][1]-hw[i,1]/2,centres[i][0]-hw[i,0]/2),hw[i,1],hw[i,0],linewidth=1,edgecolor='r',facecolor='none')\n",
        "  ax.add_patch(rect)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of boxes with IoU > threshold (0.5): 6\n",
            "Green box: ground truth. Red box: default boxes with IoU < threshold (0.5)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nI7mXjS8zA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f461fad5-a72f-4a77-92f5-30653c5209a8"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
        "print(train_dataset.element_spec)\n",
        "print(test_dataset.element_spec)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(224, 224, 3), dtype=tf.float64, name=None), TensorSpec(shape=(3150, 5), dtype=tf.float64, name=None))\n",
            "(TensorSpec(shape=(224, 224, 3), dtype=tf.float64, name=None), TensorSpec(shape=(3150, 5), dtype=tf.float64, name=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyX8dnwQ8_1k"
      },
      "source": [
        "BATCH_SIZE = 10\n",
        "SHUFFLE_BUFFER_SIZE = 60\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE,drop_remainder=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EeBg_g29GLU"
      },
      "source": [
        "LOSS FUNCTION<br>\n",
        "Hard negative mining hasn't been done here<br>\n",
        "Initial idea was to assign weights to background classes, but there is some problem in that approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMEpljzd9CxT"
      },
      "source": [
        "# label is not required here in the standard implementation\n",
        "# calculate the smooth L1 loss\n",
        "def smoothL1(x,y,label):\n",
        "  diff = K.abs(x-y) #* K.switch(label == 10, label*1.0/BOXES, label)\n",
        "  result = K.switch(diff < 1, 0.5 * diff**2, diff - 0.5)\n",
        "  return K.mean(result)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fSUhh8O_DsK"
      },
      "source": [
        "def confidenceLoss(y,label):\n",
        "  unweighted_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(label, y)\n",
        "  # class_weights = tf.constant([[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0/BOXES]]*BOXES])\n",
        "  # weights = tf.reduce_sum(class_weights * y, axis = -1)\n",
        "  # weighted_loss = unweighted_loss * weights\n",
        "  return K.mean(unweighted_loss)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn0xh6OX_BvN"
      },
      "source": [
        "def Loss(gt,y):\n",
        "  # shape of y is n * BOXES * output_channels\n",
        "  # shape of gt is n * BOXES * 5 \n",
        "  loss = 0\n",
        "  # localisation loss\n",
        "  loss += smoothL1(y[:,:,-4:],gt[:,:,-4:],gt[:,:,0:1])\n",
        "  # confidence loss\n",
        "  loss += confidenceLoss(y[:,:,:-4],tf.cast(gt[:,:,0],tf.int32))\n",
        "  return loss"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8_O3V8DB_Gk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c74056-5226-45a7-cf70-fa004d203946"
      },
      "source": [
        "base_learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),loss=Loss)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7pp6Fp9DDWm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39ca0340-fe39-4016-da7d-1ca95148010b"
      },
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    epochs=25,\n",
        "                    validation_data = test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "WARNING:tensorflow:Layer ssd is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B5_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand/kernel:0', 'mobile_netv2_1/conv_out/kernel:0', 'mobile_netv2_1/conv_seg/kernel:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B5_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand/kernel:0', 'mobile_netv2_1/conv_out/kernel:0', 'mobile_netv2_1/conv_seg/kernel:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B5_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand/kernel:0', 'mobile_netv2_1/conv_out/kernel:0', 'mobile_netv2_1/conv_seg/kernel:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B5_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand/kernel:0', 'mobile_netv2_1/conv_out/kernel:0', 'mobile_netv2_1/conv_seg/kernel:0'] when minimizing the loss.\n",
            "60/60 [==============================] - 11s 181ms/step - loss: 0.3415 - val_loss: 0.2681\n",
            "Epoch 2/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0890 - val_loss: 0.0674\n",
            "Epoch 3/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0528 - val_loss: 0.0564\n",
            "Epoch 4/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0457 - val_loss: 0.0455\n",
            "Epoch 5/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0764 - val_loss: 0.0467\n",
            "Epoch 6/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0215 - val_loss: 0.0264\n",
            "Epoch 7/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0241 - val_loss: 0.0191\n",
            "Epoch 8/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0384 - val_loss: 0.0180\n",
            "Epoch 9/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0250 - val_loss: 0.0160\n",
            "Epoch 10/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0333 - val_loss: 0.0145\n",
            "Epoch 11/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0143 - val_loss: 0.0134\n",
            "Epoch 12/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0207 - val_loss: 0.0144\n",
            "Epoch 13/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0164 - val_loss: 0.0134\n",
            "Epoch 14/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0162 - val_loss: 0.0130\n",
            "Epoch 15/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0135 - val_loss: 0.0124\n",
            "Epoch 16/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0111 - val_loss: 0.0113\n",
            "Epoch 17/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0126 - val_loss: 0.0107\n",
            "Epoch 18/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0115 - val_loss: 0.0110\n",
            "Epoch 19/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0125 - val_loss: 0.0104\n",
            "Epoch 20/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0086 - val_loss: 0.0102\n",
            "Epoch 21/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0137 - val_loss: 0.0104\n",
            "Epoch 22/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0114 - val_loss: 0.0149\n",
            "Epoch 23/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0076 - val_loss: 0.0103\n",
            "Epoch 24/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0078 - val_loss: 0.0093\n",
            "Epoch 25/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0092 - val_loss: 0.0098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_n2VfMsg1NT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e20fc8d4-968c-4272-9c62-57eeefcee1b3"
      },
      "source": [
        "model.evaluate(test_x,test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 145ms/step - loss: 0.0098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009824990294873714"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oNuY-45SngR"
      },
      "source": [
        "INFERENCE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTfYjsyJTEtv"
      },
      "source": [
        "# create some sample data\n",
        "X, Y = convert(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPazH1zFTnE4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "535d81f5-7835-47ce-98a0-6d78bfe13c78"
      },
      "source": [
        "# get prediction for one sample\n",
        "y_pred = model.predict(X)\n",
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 3150, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrD03dgjcZMO"
      },
      "source": [
        "OBJperCLASS = 10 # get the top 10 results for each class\n",
        "# get the confidence scores (with class values) and delta for the boxes. For each class, the top 10 values are used\n",
        "def infer(Y):\n",
        "  # classes are actually the index into the default boxes\n",
        "  classes = np.zeros((OBJperCLASS,outputChannels-4),dtype=np.uint16)\n",
        "  conf = np.zeros((OBJperCLASS,outputChannels-4))\n",
        "  delta = np.zeros((OBJperCLASS,outputChannels-4,4))\n",
        "  class_predictions = softmax(Y[:,:outputChannels-4],axis=1)\n",
        "  for i in range(outputChannels-4):\n",
        "    classes[:,i] = bottleneck.argpartition(class_predictions[:,i],BOXES-1-10,axis=-1)[-OBJperCLASS:]\n",
        "    conf[:,i] = class_predictions[classes[:,i],i]\n",
        "    delta[:,i] = Y[classes[:,i],outputChannels-4:]\n",
        "  return conf,classes, delta\n",
        "\n",
        "# generate bounding boxes from the inferred outputs\n",
        "def Bbox(confidence,box_idx,delta):\n",
        "  #delta contains delta(cx,cy,h,w)\n",
        "  bbox_centre = np.zeros((OBJperCLASS,outputChannels-4,2))\n",
        "  bbox_hw = np.zeros((OBJperCLASS,outputChannels-4,2))\n",
        "  for i in range(OBJperCLASS):\n",
        "    bbox_centre[i,:,0] = centres[box_idx[i]][:,0]+delta[i,:,0]\n",
        "    bbox_centre[i,:,1] = centres[box_idx[i]][:,1]+delta[i,:,1]\n",
        "    bbox_hw[i,:,0] = hw[box_idx[i]][:,0] + delta[i,:,2]\n",
        "    bbox_hw[i,:,1] = hw[box_idx[i]][:,1]+delta[i,:,3]\n",
        "  return bbox_centre,bbox_hw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY7SOlpafX51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "eef5e296-27f6-46f1-bfeb-422573f1d1e1"
      },
      "source": [
        "r = np.random.randint(TESTSIZE)\n",
        "\n",
        "# top 10 predictions for each class\n",
        "confidence, box_idx, delta = infer(y_pred[r])\n",
        "bbox_centre,bbox_hw = Bbox(confidence, box_idx, delta)\n",
        "\n",
        "im = np.array(Image.fromarray(X[r].astype(np.uint8)))\n",
        "fig,ax = plt.subplots(1)\n",
        "ax.imshow(im)\n",
        "\n",
        "for i in range(outputChannels-4):\n",
        "  # skipping backgrounds\n",
        "  if i == NUM_CLASSES:\n",
        "    continue\n",
        "  color = 'r'\n",
        "  # if a class is mentioned in the ground truth, color the boxes green\n",
        "  if i in Y[r,:,0]:\n",
        "    color = 'g'\n",
        "    print(i)\n",
        "  \n",
        "  # skip all the classes which have low confidence values\n",
        "  if (confidence[:,i] > 0.5).any() or i in Y[r,:,0]:\n",
        "    for k in range(OBJperCLASS):\n",
        "      print(\"{}: Confidence-{}\\t\\tCentre-{} Height,Width-{}\".format(i,confidence[k,i],bbox_centre[k,i],bbox_hw[k,i]))\n",
        "      \n",
        "      # draw bounding box only if confidence scores are high\n",
        "      if confidence[k,i] < 0.5:\n",
        "        continue\n",
        "      x = bbox_centre[k,i,0] - bbox_hw[k,i,0]/2\n",
        "      y = bbox_centre[k,i,1] - bbox_hw[k,i,1]/2\n",
        "      rect = patches.Rectangle((y,x),bbox_hw[k,i,1],bbox_hw[k,i,0],linewidth=1,edgecolor=color,facecolor='none')\n",
        "      ax.add_patch(rect)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "7: Confidence-0.7365235686302185\t\tCentre-[42.19794345 98.16143656] Height,Width-[32.29747125 32.31169936]\n",
            "7: Confidence-0.8857401013374329\t\tCentre-[31.7246573  91.92364167] Height,Width-[38.88492426 28.39619501]\n",
            "7: Confidence-0.9466167688369751\t\tCentre-[37.35820007 95.4094162 ] Height,Width-[28.65339181 29.04177281]\n",
            "7: Confidence-0.9956559538841248\t\tCentre-[37.51727843 93.68477857] Height,Width-[27.14049515 28.02397426]\n",
            "7: Confidence-0.9956580996513367\t\tCentre-[36.07167462 96.26651478] Height,Width-[27.35519641 40.82926547]\n",
            "7: Confidence-0.9860585927963257\t\tCentre-[36.14206849 88.0132165 ] Height,Width-[26.96784037 42.68980633]\n",
            "7: Confidence-0.9980512857437134\t\tCentre-[35.96905352 92.87503022] Height,Width-[27.35304659 40.9342879 ]\n",
            "7: Confidence-0.9995020627975464\t\tCentre-[39.372262   93.71296859] Height,Width-[28.78150412 28.83308884]\n",
            "7: Confidence-0.9984629154205322\t\tCentre-[38.21918631 94.18664432] Height,Width-[27.11899134 27.2651076 ]\n",
            "7: Confidence-0.9972821474075317\t\tCentre-[37.71326017 92.93149531] Height,Width-[29.38378605 28.26766874]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z32HPrzihVqN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}